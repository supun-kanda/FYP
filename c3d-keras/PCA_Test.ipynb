{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "file = './models/PCA_activitynet_v1-3.hdf5'\n",
    "f = h5py.File(file, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: [u'data', u'type']\n",
      "[u'S', u'U', u'_S', u'_U', u'_n_samples', u'_x_mean', u'n_samples', u'x_mean']\n"
     ]
    }
   ],
   "source": [
    "# List all groups\n",
    "print(\"Keys: %s\" % f.keys())\n",
    "a_group_key = list(f.keys())[0]\n",
    "# Get the data\n",
    "data = list(f[a_group_key])\n",
    "print(list(f['data'].keys()))\n",
    "#print(f['type'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'S', u'U', u'_S', u'_U', u'_n_samples', u'_x_mean', u'n_samples', u'x_mean']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1 = f['data']\n",
    "list(d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4096, 4096)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array((d1['U'])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCAs = np.array(d1['U'])[:,0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/supunK/anaconda3/envs/c3d/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "[Info] image_dim_order (from default ~/.keras/keras.json)=tf\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "from keras.models import model_from_json\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import c3d_model\n",
    "import sys\n",
    "import keras.backend as K\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "dim_ordering = K.image_dim_ordering()\n",
    "print \"[Info] image_dim_order (from default ~/.keras/keras.json)={}\".format(\n",
    "        dim_ordering)\n",
    "backend = dim_ordering\n",
    "\n",
    "def diagnose(data, verbose=True, label='input', plots=False, backend='tf'):\n",
    "    # Convolution3D?\n",
    "    if data.ndim > 2:\n",
    "        if backend == 'th':\n",
    "            data = np.transpose(data, (1, 2, 3, 0))\n",
    "        #else:\n",
    "        #    data = np.transpose(data, (0, 2, 1, 3))\n",
    "        min_num_spatial_axes = 10\n",
    "        max_outputs_to_show = 3\n",
    "        ndim = data.ndim\n",
    "        print \"[Info] {}.ndim={}\".format(label, ndim)\n",
    "        print \"[Info] {}.shape={}\".format(label, data.shape)\n",
    "        for d in range(ndim):\n",
    "            num_this_dim = data.shape[d]\n",
    "            if num_this_dim >= min_num_spatial_axes: # check for spatial axes\n",
    "                # just first, center, last indices\n",
    "                range_this_dim = [0, num_this_dim/2, num_this_dim - 1]\n",
    "            else:\n",
    "                # sweep all indices for non-spatial axes\n",
    "                range_this_dim = range(num_this_dim)\n",
    "            for i in range_this_dim:\n",
    "                new_dim = tuple([d] + range(d) + range(d + 1, ndim))\n",
    "                sliced = np.transpose(data, new_dim)[i, ...]\n",
    "                print(\"[Info] {}, dim:{} {}-th slice: \"\n",
    "                      \"(min, max, mean, std)=({}, {}, {}, {})\".format(\n",
    "                              label,\n",
    "                              d, i,\n",
    "                              np.min(sliced),\n",
    "                              np.max(sliced),\n",
    "                              np.mean(sliced),\n",
    "                              np.std(sliced)))\n",
    "        if plots:\n",
    "            # assume (l, h, w, c)-shaped input\n",
    "            if data.ndim != 4:\n",
    "                print(\"[Error] data (shape={}) is not 4-dim. Check data\".format(\n",
    "                        data.shape))\n",
    "                return\n",
    "            l, h, w, c = data.shape\n",
    "            if l >= min_num_spatial_axes or \\\n",
    "                h < min_num_spatial_axes or \\\n",
    "                w < min_num_spatial_axes:\n",
    "                print(\"[Error] data (shape={}) does not look like in (l,h,w,c) \"\n",
    "                      \"format. Do reshape/transpose.\".format(data.shape))\n",
    "                return\n",
    "            nrows = int(np.ceil(np.sqrt(data.shape[0])))\n",
    "            # BGR\n",
    "            if c == 3:\n",
    "                for i in range(l):\n",
    "                    mng = plt.get_current_fig_manager()\n",
    "                    mng.resize(*mng.window.maxsize())\n",
    "                    plt.subplot(nrows, nrows, i + 1) # doh, one-based!\n",
    "                    im = np.squeeze(data[i, ...]).astype(np.float32)\n",
    "                    im = im[:, :, ::-1] # BGR to RGB\n",
    "                    # force it to range [0,1]\n",
    "                    im_min, im_max = im.min(), im.max()\n",
    "                    if im_max > im_min:\n",
    "                        im_std = (im - im_min) / (im_max - im_min)\n",
    "                    else:\n",
    "                        print \"[Warning] image is constant!\"\n",
    "                        im_std = np.zeros_like(im)\n",
    "                    plt.imshow(im_std)\n",
    "                    plt.axis('off')\n",
    "                    plt.title(\"{}: t={}\".format(label, i))\n",
    "                plt.show()\n",
    "                #plt.waitforbuttonpress()\n",
    "            else:\n",
    "                for j in range(min(c, max_outputs_to_show)):\n",
    "                    for i in range(l):\n",
    "                        mng = plt.get_current_fig_manager()\n",
    "                        mng.resize(*mng.window.maxsize())\n",
    "                        plt.subplot(nrows, nrows, i + 1) # doh, one-based!\n",
    "                        im = np.squeeze(data[i, ...]).astype(np.float32)\n",
    "                        im = im[:, :, j]\n",
    "                        # force it to range [0,1]\n",
    "                        im_min, im_max = im.min(), im.max()\n",
    "                        if im_max > im_min:\n",
    "                            im_std = (im - im_min) / (im_max - im_min)\n",
    "                        else:\n",
    "                            print \"[Warning] image is constant!\"\n",
    "                            im_std = np.zeros_like(im)\n",
    "                        plt.imshow(im_std)\n",
    "                        plt.axis('off')\n",
    "                        plt.title(\"{}: o={}, t={}\".format(label, j, i))\n",
    "                    plt.show()\n",
    "                    #plt.waitforbuttonpress()\n",
    "    elif data.ndim == 1:\n",
    "        print(\"[Info] {} (min, max, mean, std)=({}, {}, {}, {})\".format(\n",
    "                      label,\n",
    "                      np.min(data),\n",
    "                      np.max(data),\n",
    "                      np.mean(data),\n",
    "                      np.std(data)))\n",
    "        print(\"[Info] data[:10]={}\".format(data[:10]))\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] Using backend=tf\n"
     ]
    }
   ],
   "source": [
    "show_images = False\n",
    "diagnose_plots = False\n",
    "model_dir = '/home/supunK/GIT/c3d-keras/models'\n",
    "global backend\n",
    "\n",
    "# override backend if provided as an input arg\n",
    "'''\n",
    "if len(sys.argv) > 1:\n",
    "    if 'tf' in sys.argv[1].lower():\n",
    "        backend = 'tf'\n",
    "    else:\n",
    "        backend = 'th'\n",
    "'''\n",
    "backend = 'tf'\n",
    "print \"[Info] Using backend={}\".format(backend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] Reading model architecture...\n",
      "WARNING:tensorflow:From /home/supunK/anaconda3/envs/c3d/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:1205: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "[Info] Loading model weights...\n",
      "[Info] Loading model weights -- DONE!\n",
      "WARNING:tensorflow:From /home/supunK/anaconda3/envs/c3d/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:1290: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "[Info] Loading labels...\n",
      "Total labels: 487\n",
      "[Info] Loading a sample video...\n",
      "(606, 128, 171, 3)\n",
      "('shape is ', (16, 128, 171, 3))\n",
      "(16, 128, 171, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c3d_model.py:77: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(64, (3, 3, 3), name=\"conv1\", activation=\"relu\", input_shape=(16, 112, ..., padding=\"same\", weights=[array([[[...)`\n",
      "  weights=model.layers[0].get_weights()))\n",
      "c3d_model.py:81: UserWarning: Update your `MaxPooling3D` call to the Keras 2 API: `MaxPooling3D(padding=\"valid\", strides=(1, 2, 2), name=\"pool1\", pool_size=(1, 2, 2))`\n",
      "  border_mode='valid', name='pool1'))\n",
      "c3d_model.py:88: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(128, (3, 3, 3), padding=\"same\", activation=\"relu\", weights=[array([[[..., name=\"conv2\")`\n",
      "  weights=model.layers[2].get_weights()))\n",
      "c3d_model.py:92: UserWarning: Update your `MaxPooling3D` call to the Keras 2 API: `MaxPooling3D(padding=\"valid\", strides=(2, 2, 2), name=\"pool2\", pool_size=(2, 2, 2))`\n",
      "  border_mode='valid', name='pool2'))\n",
      "c3d_model.py:99: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(256, (3, 3, 3), padding=\"same\", activation=\"relu\", weights=[array([[[..., name=\"conv3a\")`\n",
      "  weights=model.layers[4].get_weights()))\n",
      "c3d_model.py:104: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(256, (3, 3, 3), padding=\"same\", activation=\"relu\", weights=[array([[[..., name=\"conv3b\")`\n",
      "  weights=model.layers[5].get_weights()))\n",
      "c3d_model.py:108: UserWarning: Update your `MaxPooling3D` call to the Keras 2 API: `MaxPooling3D(padding=\"valid\", strides=(2, 2, 2), name=\"pool3\", pool_size=(2, 2, 2))`\n",
      "  border_mode='valid', name='pool3'))\n",
      "c3d_model.py:115: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(512, (3, 3, 3), padding=\"same\", activation=\"relu\", weights=[array([[[..., name=\"conv4a\")`\n",
      "  weights=model.layers[7].get_weights()))\n",
      "c3d_model.py:120: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(512, (3, 3, 3), padding=\"same\", activation=\"relu\", weights=[array([[[..., name=\"conv4b\")`\n",
      "  weights=model.layers[8].get_weights()))\n",
      "c3d_model.py:124: UserWarning: Update your `MaxPooling3D` call to the Keras 2 API: `MaxPooling3D(padding=\"valid\", strides=(2, 2, 2), name=\"pool4\", pool_size=(2, 2, 2))`\n",
      "  border_mode='valid', name='pool4'))\n",
      "c3d_model.py:131: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(512, (3, 3, 3), padding=\"same\", activation=\"relu\", weights=[array([[[..., name=\"conv5a\")`\n",
      "  weights=model.layers[10].get_weights()))\n",
      "c3d_model.py:136: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(512, (3, 3, 3), padding=\"same\", activation=\"relu\", weights=[array([[[..., name=\"conv5b\")`\n",
      "  weights=model.layers[11].get_weights()))\n",
      "c3d_model.py:141: UserWarning: Update your `MaxPooling3D` call to the Keras 2 API: `MaxPooling3D(padding=\"valid\", strides=(2, 2, 2), name=\"pool5\", pool_size=(2, 2, 2))`\n",
      "  border_mode='valid', name='pool5'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Debug] at layer=fc7: output.shape=(4096,)\n",
      "[Info] fc7 activation (min, max, mean, std)=(0.0, 3.4830904007, 0.187883943319, 0.444548994303)\n",
      "[Info] data[:10]=[0.         0.1508323  0.         0.06676114 0.         0.\n",
      " 0.         0.16062343 0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "if backend == 'th':\n",
    "    model_weight_filename = os.path.join(model_dir, 'sports1M_weights_th.h5')\n",
    "    model_json_filename = os.path.join(model_dir, 'sports1M_weights_th.json')\n",
    "else:\n",
    "    model_weight_filename = os.path.join(model_dir, 'sports1M_weights_tf.h5')\n",
    "    model_json_filename = os.path.join(model_dir, 'sports1M_weights_tf.json')\n",
    "\n",
    "print(\"[Info] Reading model architecture...\")\n",
    "model = model_from_json(open(model_json_filename, 'r').read())\n",
    "#model = c3d_model.get_model(backend=backend)\n",
    "\n",
    "# visualize model\n",
    "model_img_filename = os.path.join(model_dir, 'c3d_model.png')\n",
    "if not os.path.exists(model_img_filename):\n",
    "    from keras.utils import plot_model\n",
    "    plot_model(model, to_file=model_img_filename)\n",
    "\n",
    "print(\"[Info] Loading model weights...\")\n",
    "model.load_weights(model_weight_filename)\n",
    "print(\"[Info] Loading model weights -- DONE!\")\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd')\n",
    "\n",
    "print(\"[Info] Loading labels...\")\n",
    "with open('sports1m/labels.txt', 'r') as f:\n",
    "    labels = [line.strip() for line in f.readlines()]\n",
    "print('Total labels: {}'.format(len(labels)))\n",
    "\n",
    "print(\"[Info] Loading a sample video...\")\n",
    "#cap = cv2.VideoCapture('dM06AMFLsrc.mp4')\n",
    "cap = cv2.VideoCapture('test.mp4')\n",
    "\n",
    "vid = []\n",
    "while True:\n",
    "    ret, img = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    vid.append(cv2.resize(img, (171, 128)))\n",
    "vid = np.array(vid, dtype=np.float32)\n",
    "\n",
    "#plt.imshow(vid[2000]/256)\n",
    "#plt.show()\n",
    "print(vid.shape)\n",
    "# sample 16-frame clip\n",
    "#start_frame = 100\n",
    "#start_frame = 2000\n",
    "start_frame = 0\n",
    "X = vid[start_frame:(start_frame + 16), :, :, :]\n",
    "print(\"shape is \", X.shape)\n",
    "#diagnose(X, verbose=True, label='X (16-frame clip)', plots=show_images)\n",
    "\n",
    "# subtract mean\n",
    "mean_cube = np.load('models/train01_16_128_171_mean.npy')\n",
    "mean_cube = np.transpose(mean_cube, (1, 2, 3, 0))\n",
    "print(mean_cube.shape)\n",
    "#diagnose(mean_cube, verbose=True, label='Mean cube', plots=show_images)\n",
    "X -= mean_cube\n",
    "#diagnose(X, verbose=True, label='Mean-subtracted X', plots=show_images)\n",
    "\n",
    "# center crop\n",
    "X = X[:, 8:120, 30:142, :] # (l, h, w, c)\n",
    "#diagnose(X, verbose=True, label='Center-cropped X', plots=show_images)\n",
    "\n",
    "if backend == 'th':\n",
    "    X = np.transpose(X, (3, 0, 1, 2)) # input_shape = (3,16,112,112)\n",
    "else:\n",
    "    pass                              # input_shape = (16,112,112,3)\n",
    "\n",
    "# get activations for intermediate layers if needed\n",
    "inspect_layers = [\n",
    "#    'fc6',\n",
    "    'fc7',\n",
    "    ]\n",
    "####################################################################################\n",
    "############################My Code#################################################\n",
    "sys.path.insert(0,'/home/supunK/GIT/c3d-keras/models' )\n",
    "\n",
    "from give_arr import arr\n",
    "out = arr()\n",
    "\n",
    "####################################################################################\n",
    "####################################################################################\n",
    "for layer in inspect_layers:\n",
    "    int_model = c3d_model.get_int_model(model=model, layer=layer, backend=backend)\n",
    "    int_output = int_model.predict_on_batch(np.array([X]))\n",
    "    int_output = int_output[0, ...]\n",
    "    print \"[Debug] at layer={}: output.shape={}\".format(layer, int_output.shape)\n",
    "    diagnose(int_output,\n",
    "             verbose=True,\n",
    "             label='{} activation'.format(layer),\n",
    "             plots=diagnose_plots,\n",
    "             backend=backend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_out = int_output.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced = np.dot(new_out,PCAs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 500)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
